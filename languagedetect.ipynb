{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First step of CLEANING\n",
    "\n",
    "1. identify all languages present in corpus (8700+ are english)\n",
    "    - using spacy langdetect\n",
    "    - separate docs by language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# spacy libs \n",
    "import spacy\n",
    "from spacy.language import Language\n",
    "from spacy.lang.en import English\n",
    "from spacy_langdetect import LanguageDetector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only run once! \n",
    "@Language.factory(\"language_detector\")\n",
    "\n",
    "def get_lang_detector(nlp, name):\n",
    "   return LanguageDetector()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"wcpr_mypersonality.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use spacy lang detect to detect languages of status \n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "nlp.add_pipe('language_detector', last=True)\n",
    "langs = []\n",
    "for sent in list(df['STATUS']):\n",
    "    p = nlp(sent)._.language\n",
    "    langs.append(p['language'])\n",
    "\n",
    "df['lang'] = langs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# just english\n",
    "df1 = df[df['lang']=='en']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new english only file to use\n",
    "df1.to_csv(\"en_personality.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We manually checked all text with non-English labels after this and merged the misclassified English samples back with the en file for further cleaning."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
