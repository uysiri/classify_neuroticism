{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spellchecker file \n",
    "\n",
    "- Do spellcheck here on English text then save to new file for more cleaning\n",
    "- since jamspell may vary each time its run on the same text so don't run again because the same results are not guaranteed "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# to install jamspell --> pip install swig==3.0.6 , pip install jamspell\n",
    "import jamspell\n",
    "# nltk langs\n",
    "import nltk\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from nltk.sentiment.util import *\n",
    "from nltk import tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-21 16:21:03.834474: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "from spacy.language import Language\n",
    "from spacy.lang.en import English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in \n",
    "df = pd.read_csv(\"en_personality.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                          likes the sound of thunder.\n",
       "1    is so sleepy it's not even funny that's she ca...\n",
       "2    is sore and wants the knot of muscles at the b...\n",
       "Name: STATUS, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make status all lowercase \n",
    "df['STATUS'] = df['STATUS'].str.lower()\n",
    "df['STATUS'].head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenize to see how many unique words before spellchecking \n",
    "tokens = []\n",
    "nlp = English(parser=False)\n",
    "nlp.tokenizer.rules = {key: value for key, value in nlp.tokenizer.rules.items() if \"'\" not in key and \"’\" not in key and \"‘\" not in key}\n",
    "\n",
    "for word in list(df['STATUS']):\n",
    "    doc=nlp(word)\n",
    "    toke = [token.text for token in doc]\n",
    "    tokens.append(toke)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "flat = [val for sublist in tokens for val in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15059"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# unique words.. yikes\n",
    "len(set(flat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load jamspell model\n",
    "corrector = jamspell.TSpellCorrector()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# had to download trained model as a local file :(\n",
    "corrector.LoadLangModel('/Users/irisyu/Downloads/en.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrected = []\n",
    "for line in list(df['STATUS']):\n",
    "    correction = corrector.FixFragment(line)\n",
    "    corrected.append(correction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "newtoke = []\n",
    "for word in corrected:\n",
    "    doc=nlp(word)\n",
    "    toke = [token.text for token in doc]\n",
    "    newtoke.append(toke)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "174564\n",
      "14188\n"
     ]
    }
   ],
   "source": [
    "newflat = [val for sublist in newtoke for val in sublist]\n",
    "print(len(newflat))\n",
    "print(len(set(newflat)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['corrected'] = corrected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save spellchecked file to csv for next step!\n",
    "df.to_csv(\"en_personality_spellcheck.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
